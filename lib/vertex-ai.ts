import { VertexAI } from "@google-cloud/vertexai";
import { GoogleAuth } from "google-auth-library";
import fetch from "node-fetch";
import { 
  getAnalysisPrompt, 
  getGenerationPrompt, 
  getSpaceTypeDetectionPrompt,
  normalizeSpaceType,
  PromptType,
  SpaceType 
} from "./prompts";

// Configuration - Lazy loading pour permettre le chargement des variables d'environnement
function getProjectId(): string {
  const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID;
  if (!projectId) {
    throw new Error("GOOGLE_CLOUD_PROJECT_ID is required");
  }
  return projectId;
}

function getLocation(): string {
  return process.env.GCP_LOCATION || "us-central1";
}

// Initialiser Vertex AI (lazy)
let vertexAIInstance: VertexAI | null = null;
function getVertexAI(): VertexAI {
  if (!vertexAIInstance) {
    vertexAIInstance = new VertexAI({
      project: getProjectId(),
      location: getLocation(),
    });
  }
  return vertexAIInstance;
}

// Initialiser Google Auth pour l'API REST (lazy)
let authInstance: GoogleAuth | null = null;
function getAuth(): GoogleAuth {
  if (!authInstance) {
    authInstance = new GoogleAuth({
      scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    });
  }
  return authInstance;
}

/**
 * D√©tecte le type d'espace dans l'image
 */
async function detectSpaceType(imageBuffer: Buffer): Promise<SpaceType> {
  try {
    console.log("üîé D√©tection du type d'espace...");

    const vertexAI = getVertexAI();
    const model = vertexAI.preview.getGenerativeModel({
      model: "gemini-2.0-flash-exp",
    });

    const base64Image = imageBuffer.toString("base64");
    const detectionPrompt = getSpaceTypeDetectionPrompt();

    const request = {
      contents: [
        {
          role: "user",
          parts: [
            {
              inlineData: {
                mimeType: "image/jpeg",
                data: base64Image,
              },
            },
            {
              text: detectionPrompt,
            },
          ],
        },
      ],
    };

    const response = await model.generateContent(request);
    const detectionText =
      response.response.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || "";

    if (!detectionText) {
      console.log("‚ö†Ô∏è Aucune d√©tection retourn√©e, utilisation du mode auto");
      return "auto";
    }

    const spaceType = normalizeSpaceType(detectionText);
    console.log(`‚úÖ Type d'espace d√©tect√©: ${spaceType}`);
    return spaceType;
  } catch (error) {
    console.error("‚ö†Ô∏è Erreur lors de la d√©tection du type d'espace:", error);
    console.log("‚ö†Ô∏è Utilisation du mode auto par d√©faut");
    return "auto";
  }
}

/**
 * Analyse une image avec Gemini Vision
 * Retourne une description d√©taill√©e de la pi√®ce en d√©sordre
 * D√©tecte automatiquement le type d'espace pour utiliser les prompts sp√©cialis√©s
 */
export async function analyzeMessyRoom(imageBuffer: Buffer): Promise<string> {
  try {
    console.log("üîç Analyse de l'image avec Gemini Vision...");

    // √âtape 1: D√©tecter le type d'espace
    const spaceType = await detectSpaceType(imageBuffer);

    // √âtape 2: Utiliser le prompt sp√©cialis√© pour ce type d'espace
    const vertexAI = getVertexAI();
    const model = vertexAI.preview.getGenerativeModel({
      model: "gemini-2.0-flash-exp",
    });

    const base64Image = imageBuffer.toString("base64");
    const prompt = getAnalysisPrompt(spaceType);

    console.log(`üìã Utilisation du prompt sp√©cialis√© pour: ${spaceType}`);

    const request = {
      contents: [
        {
          role: "user",
          parts: [
            {
              inlineData: {
                mimeType: "image/jpeg",
                data: base64Image,
              },
            },
            {
              text: prompt,
            },
          ],
        },
      ],
    };

    const response = await model.generateContent(request);
    const analysisText =
      response.response.candidates?.[0]?.content?.parts?.[0]?.text || "";

    if (!analysisText) {
      throw new Error("Aucune analyse retourn√©e par Gemini");
    }

    console.log(
      "‚úÖ Analyse compl√©t√©e:",
      analysisText.substring(0, 100) + "..."
    );
    return analysisText;
  } catch (error) {
    console.error("‚ùå Erreur lors de l'analyse:", error);
    throw new Error(`√âchec de l'analyse de l'image: ${error}`);
  }
}

/**
 * G√©n√®re une image "nettoy√©e" avec Imagen 3 via l'API REST
 * Utilise l'image originale comme r√©f√©rence pour pr√©server la structure exacte (comme Nano Banana)
 */
export async function generateCleanImage(
  analysis: string,
  promptType: PromptType = "realistic",
  originalImageBuffer?: Buffer,
  spaceType: SpaceType = "auto"
): Promise<Buffer> {
  try {
    console.log("üé® G√©n√©ration de l'image avec Imagen 3...");
    if (originalImageBuffer) {
      console.log("üì∏ Utilisation de l'image originale comme r√©f√©rence (mode image-to-image)");
    }

    // Si le type d'espace n'est pas fourni et qu'on a l'image, le d√©tecter
    if (spaceType === "auto" && originalImageBuffer) {
      spaceType = await detectSpaceType(originalImageBuffer);
    }

    const generationPrompt = getGenerationPrompt(promptType, analysis, spaceType);
    console.log(`üè† Type d'espace utilis√©: ${spaceType}`);

    // URL de l'API Imagen 3
    const projectId = getProjectId();
    const location = getLocation();
    const model = "imagen-3.0-generate-002"; // Utiliser la version 002
    const apiUrl = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${model}:predict`;

    // Obtenir le token d'authentification
    const auth = getAuth();
    const client = await auth.getClient();
    const token = await client.getAccessToken();

    if (!token.token) {
      throw new Error("Impossible d'obtenir le token d'authentification");
    }

    // Pr√©parer la requ√™te avec image de r√©f√©rence si disponible
    const instance: any = {
      prompt: generationPrompt,
    };

    // Si on a l'image originale, l'utiliser comme r√©f√©rence (image-to-image)
    // Cela permet de pr√©server la structure exacte comme Nano Banana
    if (originalImageBuffer) {
      const base64Image = originalImageBuffer.toString("base64");
      instance.baseImage = {
        bytesBase64Encoded: base64Image,
      };
      // Ajouter un param√®tre de force pour l'√©dition d'image
      // Plus la valeur est √©lev√©e, plus l'image g√©n√©r√©e ressemble √† l'originale
      instance.imageEditingStrength = 0.7; // 0.0 = nouvelle image, 1.0 = tr√®s proche de l'original
    }

    const requestBody = {
      instances: [instance],
      parameters: {
        sampleCount: 1,
        aspectRatio: "1:1", // Options: '1:1', '16:9', '9:16', '4:3', '3:4'
        negativePrompt:
          "blurry, low quality, distorted, unrealistic, cartoonish, anime, drawing, painting, rendered, artificial, fake, oversaturated, overexposed",
        safetyFilterLevel: "block_some",
        personGeneration: "dont_allow",
        // Param√®tres am√©lior√©s pour une meilleure qualit√© (style Nano Banana)
        guidanceScale: 7.5, // Contr√¥le la fid√©lit√© au prompt (plus √©lev√© = plus fid√®le)
        seed: undefined, // Peut √™tre d√©fini pour la reproductibilit√©
      },
    };

    console.log("üì§ Envoi de la requ√™te √† Imagen 3...");

    // Appel √† l'API REST avec node-fetch
    const response = await fetch(apiUrl, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${token.token}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      let errorText: string;
      try {
        errorText = await response.text();
      } catch (e) {
        errorText = `Erreur HTTP ${response.status}`;
      }
      console.error("‚ùå Erreur API Imagen:", errorText);
      throw new Error(
        `Erreur API Imagen (${response.status}): ${errorText.substring(0, 200)}`
      );
    }

    let data: any;
    try {
      const responseText = await response.text();
      // V√©rifier si c'est du JSON valide
      if (responseText.trim().startsWith("<!DOCTYPE") || responseText.trim().startsWith("<html")) {
        throw new Error("R√©ponse HTML re√ßue au lieu de JSON - l'API a probablement retourn√© une page d'erreur");
      }
      data = JSON.parse(responseText);
    } catch (parseError: any) {
      console.error("‚ùå Erreur parsing r√©ponse Imagen:", parseError);
      throw new Error(`Erreur parsing r√©ponse API: ${parseError.message}`);
    }

    // V√©rifier la structure de la r√©ponse
    if (
      !data.predictions ||
      !Array.isArray(data.predictions) ||
      data.predictions.length === 0
    ) {
      console.error("‚ùå Structure de r√©ponse inattendue:", JSON.stringify(data));
      throw new Error("Aucune pr√©diction retourn√©e par Imagen");
    }

    const prediction = data.predictions[0];

    // La r√©ponse peut contenir bytesBase64Encoded ou une autre structure
    let imageBase64: string;

    if (prediction.bytesBase64Encoded) {
      imageBase64 = prediction.bytesBase64Encoded;
    } else if (prediction.image) {
      imageBase64 = prediction.image;
    } else if (typeof prediction === "string") {
      imageBase64 = prediction;
    } else {
      console.error("‚ùå Format de r√©ponse inattendu:", prediction);
      throw new Error("Format d'image non reconnu dans la r√©ponse");
    }

    // Convertir base64 en Buffer
    const imageBuffer = Buffer.from(imageBase64, "base64");

    if (imageBuffer.length === 0) {
      throw new Error("L'image g√©n√©r√©e est vide");
    }

    console.log(`‚úÖ Image g√©n√©r√©e avec succ√®s (${imageBuffer.length} bytes)`);
    return imageBuffer;
  } catch (error: any) {
    console.error("‚ùå Erreur lors de la g√©n√©ration:", error);
    throw new Error(`√âchec de la g√©n√©ration d'image: ${error.message || error}`);
  }
}

/**
 * Flux complet: Analyse + G√©n√©ration
 * Utilise l'image originale comme r√©f√©rence pour pr√©server la structure (comme Nano Banana)
 * D√©tecte automatiquement le type d'espace pour optimiser le traitement
 */
export async function processImageTransformation(
  imageBuffer: Buffer,
  promptType: PromptType = "realistic"
): Promise<{ generatedImage: Buffer; analysis: string }> {
  // √âtape 0: D√©tecter le type d'espace une seule fois
  console.log("üîé √âtape 0/3: D√©tection du type d'espace...");
  const spaceType = await detectSpaceType(imageBuffer);

  // √âtape 1: Analyser l'image avec Gemini Vision pour obtenir une description d√©taill√©e
  console.log("üìä √âtape 1/3: Analyse de l'image originale...");
  const analysis = await analyzeMessyRoom(imageBuffer);

  // √âtape 2: G√©n√©rer l'image nettoy√©e en utilisant l'image originale comme r√©f√©rence
  // Cela permet de pr√©server la structure exacte de la pi√®ce (comme Nano Banana)
  console.log("üé® √âtape 2/3: G√©n√©ration de l'image nettoy√©e...");
  const generatedImage = await generateCleanImage(
    analysis,
    promptType,
    imageBuffer, // Passer l'image originale comme r√©f√©rence
    spaceType // Utiliser le type d√©tect√©
  );

  console.log("‚úÖ Transformation compl√©t√©e");
  return { generatedImage, analysis };
}

